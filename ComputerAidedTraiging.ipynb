{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Created on Wed Sep 11 16:13:02 2019\n",
    "\n",
    "The code presented here is a simplified piece of code used for traiging of screening breast MRI in women with extremly dense breast\n",
    "as published in Radiology 2021 \"Deep Learning for Automated Triaging of 4581 Breast MRI Examinations from the DENSE Trial\"\n",
    "\n",
    "Citation: {Verburg, E., van Gils, C. H., van der Velden, B. H., Bakker, M. F., Pijnappel, R. M., Veldhuis, W. B., & Gilhuijs, K. G. (2022). Deep learning for automated triaging of 4581 breast MRI examinations from the DENSE trial. Radiology, 302(1), 29-36.}\n",
    "\n",
    "#INPUT\n",
    "Multiple input files are required to run the code. \n",
    "-The model weights\n",
    "-Input images\n",
    "\n",
    "The  model weights resulted form the train data which was used in for publication is enclosed. Because 8 fold internal external valiation\n",
    "was completed 8 weightfiles are present. In addition to that also a weight file is added were all data is used to train the model.\n",
    "\n",
    "Enclosed are also three example images which can be traiged by the model. The images are Maximal intensity projection (MIP) of one breast in Sagital\n",
    "transversal and coronal direction. The MIP images are prepared as described in the publication. In the outcomes in the publication was the average outcome over the three MIP directions.\n",
    "\n",
    "#OUTPUT\n",
    "Output of the model are probabilities for lesion presence and SHAP images showing the areas on which the prediction in based.\n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "Copyright (c) 2023 UMC Utrecht\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person\n",
    " obtaining a copy of this software and associated documentation\n",
    " files (the \"Software\"), to deal in the Software without\n",
    " restriction, including without limitation the rights to use,\n",
    " copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " copies of the Software, and to permit persons to whom the\n",
    " Software is furnished to do so, subject to the following\n",
    " conditions:\n",
    "\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n",
    " OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n",
    " HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n",
    " WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    " FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n",
    " OTHER DEALINGS IN THE SOFTWARE.\n",
    "################################################\n",
    "\n",
    "@author: Erik Verburg\n",
    "\"\"\"\n",
    "\n",
    "#inputs:\n",
    "# model weights can be downloaded from: https://github.com/Lab-Translational-Cancer-Imaging/AI_TriagingDENSE\n",
    "model_weights=#\"Weightfiles\\weights_1_modelweighs.hdf5\"\n",
    "\n",
    "\n",
    "#Input image files, MIP images in three directions:\n",
    "filename_cor=#\"ExampleImages\\left_Uptake0_MIP_cor.nii.gz\"\n",
    "filename_tra=#\"ExampleImages\\left_Uptake0_MIP_tra.nii.gz\"\n",
    "filename_sag=#\"ExampleImages\\left_Uptake0_MIP_sag.nii.gz\"\n",
    "\n",
    "#Import settings and functions\n",
    "import numpy as np\n",
    "import keras\n",
    "import glob\n",
    "import random\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import shutil\n",
    "import SimpleITK as sitk\n",
    "import PIL\n",
    "import shap\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "from tf_explain.callbacks.grad_cam import GradCAMCallback\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "\n",
    "\n",
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op =tf.metrics.auc(y_true, y_pred)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value\n",
    "    \n",
    "def specificity_at_sensitivity(sensitivity, **kwargs):\n",
    "    def metric(labels, predictions):\n",
    "        # any tensorflow metric\n",
    "        value, update_op = tf.compat.v1.metrics.specificity_at_sensitivity(labels, predictions, sensitivity, **kwargs)\n",
    "\n",
    "        # find all variables created for this metric\n",
    "        metric_vars = [i for i in tf.local_variables() if 'specificity_at_sensitivity' in i.name.split('/')[2]]\n",
    "\n",
    "        # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "        # They will be initialized for new session.\n",
    "        for v in metric_vars:\n",
    "            tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "        # force to update metric values\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "            return value\n",
    "    return metric        \n",
    "\n",
    "keras.metrics.auc_roc = auc_roc\n",
    "keras.metrics.metric = specificity_at_sensitivity(0.9,num_thresholds=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start compilation\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 256, 256, 128)     1280      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 1,345,922\n",
      "Trainable params: 1,345,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Set up of the deeplearning model and load the modelweights.\n",
    "\n",
    "#Optimal settings obtained using NNI.\n",
    "Direction=\"25Dimesional\"\n",
    "View=\"Single\"\n",
    "layer_size= 128\n",
    "conv_layer = 5\n",
    "optimizer=\"Adam\"\n",
    "conv_size=3\n",
    "lossfunction=\"crossentropy\"\n",
    "lrate=0.00008122008474925512\n",
    "batchsize=2\n",
    "augmentation=\"none\"\n",
    "NConvlayersinBlock=2\n",
    "DropoutRate=0.16491226911610724\n",
    "DenseLayer=0\n",
    "DenseLayer_size=16\n",
    "n_channels=1\n",
    "normalisation=\"Yes\"\n",
    "dilation=0\n",
    "dense_layer=0\n",
    "dropout=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(layer_size, (conv_size, conv_size), padding = 'same',activation='relu', input_shape=(256, 256, n_channels)))\n",
    "model.add(Conv2D(layer_size, (conv_size, conv_size), padding = 'same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(layer_size, (conv_size, conv_size), padding = 'same',activation='relu'))\n",
    "model.add(Conv2D(layer_size, (conv_size, conv_size), padding = 'same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "dilationrate=1\n",
    "   \n",
    "for l in range(conv_layer-2):\n",
    "    \n",
    "    model.add(Conv2D(layer_size, (conv_size, conv_size),dilation_rate=dilationrate, padding = 'same',activation='relu'))\n",
    "    model.add(Conv2D(layer_size, (conv_size,conv_size),dilation_rate=dilationrate, padding = 'same',activation='relu'))\n",
    "    if NConvlayersinBlock>2:\n",
    "        model.add(Conv2D(layer_size, (conv_size, conv_size), padding = 'same',activation='relu'))\n",
    "    if  NConvlayersinBlock>3:   \n",
    "        model.add(Conv2D(layer_size, (conv_size, conv_size), padding = 'same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "#model.add(Dense(2,activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "if lossfunction=='crossentropy':\n",
    "    if optimizer=='Adam':\n",
    "        print(\"start compilation\")\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "           optimizer=keras.optimizers.Adam(lr = lrate),\n",
    "           metrics=['accuracy',auc_roc,specificity_at_sensitivity(0.9,num_thresholds=2000)])\n",
    "    \n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "              \n",
    "model.load_weights(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions for image loading\n",
    "\n",
    "def Niigz2NP(filename):\n",
    "    reader = sitk.ImageFileReader()\n",
    "\n",
    "    reader.SetFileName(filename)\n",
    "    image = reader.Execute();\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    if len(array.shape)==2:\n",
    "        array = np.swapaxes(array, 0, 1)\n",
    "    elif len(array.shape)==3:\n",
    "        array = np.swapaxes(array, 0, 2)\n",
    "    \n",
    "    array=array.astype('int16') \n",
    "    \n",
    "    return(array)\n",
    "\n",
    "\n",
    "def SaveNP2Nii(array,outname):\n",
    "    \n",
    "    if len(array.shape)==2:\n",
    "        array = np.swapaxes(array, 0, 1)\n",
    "    elif len(array.shape)==3:\n",
    "        array = np.swapaxes(array, 0, 2)\n",
    "    \n",
    "    im = sitk.GetImageFromArray(array, isVector=False)\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    writer.SetFileName(outname)\n",
    "    writer.Execute(im)\n",
    "    \n",
    "\n",
    "if \"Yes\" in normalisation:\n",
    "    def norma(data):\n",
    "        return((data - data.mean()) / data.std())\n",
    "else:\n",
    "    def norma(data):\n",
    "        return(data)\n",
    "\n",
    "def padImg(img, patchSize):\n",
    "    \"\"\"Zero-pads images TO a certain size\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : ndarray\n",
    "        Image to be padded\n",
    "    patchSize : tuple or ndarray, optional\n",
    "        Patchsize of output.\n",
    "        Note: behaviour with odd patchsizes (i.e. not even) undefined\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        The padded image\n",
    "    \"\"\"\n",
    "    # First determine amount of dimensions unspecified\n",
    "    nFullDims = img.ndim - len(patchSize)\n",
    "\n",
    "    # if not all(pat > im for im, pat in zip(reversed(img.shape),\n",
    "    #                                        reversed(patchSize))):\n",
    "    #     print(img.shape, patchSize)\n",
    "    #     raise ValueError('Doesnt fit?')\n",
    "\n",
    "    # First determine dimensions of new array\n",
    "    #  WHICH IS patchsize\n",
    "    # new_size = img.shape[:nFullDims] + \\\n",
    "    #     tuple(reversed(tuple(pat for pat in reversed(patchSize))))\n",
    "    # Initialize array\n",
    "    padimg2 = np.zeros(img.shape[:nFullDims] + patchSize)\n",
    "    \n",
    "    \"\"\"\n",
    "    Below looks quite complicated, but there is logic behind it!\n",
    "    Basically we have two kinds of dimensions: the first kind are\n",
    "    the dimensions that should be copied over in full without\n",
    "    padding or anything, as they are not specified in the patch size.\n",
    "    The dimensions that ARE to be padded, we use the reverse-reverse\n",
    "    trick to determine the starting and ending position. The ending\n",
    "    position is half the patchsize (== padding size), end size is trivial.\n",
    "    \"\"\"\n",
    "    padimg2[tuple([*tuple(slice(0, p) for p in img.shape[:nFullDims]),\n",
    "                   *tuple(reversed(tuple(\n",
    "                       slice(max(0, (pat - im) // 2),\n",
    "                             max(0, (pat - im) // 2) + im)\n",
    "                       for im, pat in zip(reversed(img.shape[nFullDims:]),\n",
    "                                          reversed(patchSize))\n",
    "                   )\n",
    "                   ))])] = \\\n",
    "        img[tuple([*tuple(slice(0, p) for p in img.shape[:nFullDims]),\n",
    "                   *tuple(reversed(tuple(\n",
    "                       slice(0, min(im, pat))  # Get smallest dim\n",
    "                       for im, pat in zip(reversed(img.shape[nFullDims:]),\n",
    "                                          reversed(patchSize))\n",
    "                   )\n",
    "                   ))])]\n",
    "\n",
    "    \n",
    "    return padimg2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilty lesion presence in coronal uptake MIP = 0.48781636\n",
      "probabilty lesion presence in transversal uptake MIP = 0.9816363\n",
      "probabilty lesion presence in sagital uptake MIP = 0.91186816\n",
      "\n",
      "\n",
      "Average probability for lesions presence over three directions = 0.7937735716501871\n"
     ]
    }
   ],
   "source": [
    "#apply model on images\n",
    "\n",
    "IDS=[filename_cor[0],filename_tra[0],filename_sag[0]]\n",
    "\n",
    "dim1=256\n",
    "dim2=256\n",
    "x_test=np.empty((1,dim1,dim2,1))\n",
    "x_test[0,:,:,0]=norma(padImg(Niigz2NP(filename_cor[0]),(dim1,dim2)))\n",
    "outcome_cor= model.predict(x_test)\n",
    "\n",
    "print(\"probabilty lesion presence in coronal uptake MIP = \"  + str(outcome_cor[0][1]))\n",
    "\n",
    "dim1=256\n",
    "dim2=256\n",
    "x_test=np.empty((1,dim1,dim2,1))\n",
    "x_test[0,:,:,0]=norma(padImg(Niigz2NP(filename_tra[0]),(dim1,dim2)))\n",
    "outcome_tra= model.predict(x_test)\n",
    "\n",
    "print(\"probabilty lesion presence in transversal uptake MIP = \"  + str(outcome_tra[0][1]))\n",
    "\n",
    "dim1=256\n",
    "dim2=256\n",
    "x_test=np.empty((1,dim1,dim2,1))\n",
    "x_test[0,:,:,0]=norma(padImg(Niigz2NP(filename_sag[0]),(dim1,dim2)))\n",
    "outcome_sag= model.predict(x_test)\n",
    "\n",
    "print(\"probabilty lesion presence in sagital uptake MIP = \"  + str(outcome_sag[0][1]))\n",
    "print(\"\\n\")\n",
    "print(\"Average probability for lesions presence over three directions = \" + str((outcome_sag[0][1]+outcome_tra[0][1]+outcome_cor[0][1])/3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use SHAP to display the areas were the probabilty for lesion presence is based on.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dim1=256\n",
    "dim2=256\n",
    "numberofbackgrounds=3\n",
    "\n",
    "iter=0\n",
    "x_train=np.empty((numberofbackgrounds,dim1,dim2,1))\n",
    "\n",
    "for ID in IDS[0:numberofbackgrounds]:\n",
    "    x_train[iter,:,:,0]=norma(padImg(Niigz2NP(ID ),(dim1,dim2)))\n",
    "\n",
    "    iter+=1\n",
    "\n",
    "background = x_train\n",
    "\n",
    "# explain predictions of the model \n",
    "e = shap.DeepExplainer(model, background)\n",
    "\n",
    "print('succes')\n",
    "\n",
    "iter=0\n",
    "for ID in IDS:\n",
    "    x_test[iter,:,:,0]=norma(padImg(Niigz2NP( ID ),(dim1,dim2)))\n",
    "    \n",
    "\n",
    "    print(ID)\n",
    "    \n",
    "    shap_values = e.shap_values(x_test)\n",
    "    \n",
    "    shap.image_plot(shap_values, x_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "19721c4e509a2211067742a48e23fac6153ee82745d92609076f27566df156a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
